Using Large Language Models to simulate debates
Ken Kahn <toontalk@gmail.com> home page
Update: ChatGPT-4 can do this without help
For most large language models you can’t get a good result from just giving instructions like the following
I would like to simulate a debate. Ask me for a proposition and then generate the arguments for the pro and con teams, their rebuttals to each other, and their summarizing their position.


However, ChatGPT 4 can do this very well (PDF of log). Claude 2 did well but neglected to generate the summary for the con team. Chat 3.5 and Bing Chat misunderstood the directions. Bard picked its own proposition and only generated one rebuttal and summary. All experiments performed on 11/8/2023.
Background
I built a virtual debate generator as an exercise to explore the kinds of things one can do with the Snap! blocks that I made to interface with GPT-3, Jurassic 1, and Cohere. These large language models can generate completions to a “prompt”. For example:
  

Generating arguments, refutations, new arguments, and summaries
After asking the user for a topic for the debate I begin with this prompt:  


After this is run with for each team, I use this prompt to generate refutations:
  

Where ‘initial arguments’ were recorded during the earlier phase.


Next to get the teams to generate additional arguments this prompt is used:
  



After generating most of the debates, I added a final phase where each team presents a summary:
  

To see a sample summary visit We should subsidize preschool
Results


Some experiments can be found here. All of them used the davinci GPT-3 model with temperature set to 0.5 unless otherwise noted. They were not specially selected and no outputs were rejected.  Some are common debate topics where the models may have been trained on transcripts of these debates. For example Standardized tests should be eliminated from schools and Artificial intelligence research should be slowed down. Others are also controversial topics such as It is OK for people to eat octopus that the model may have encountered.


I experimented with what are probably novel debate topics and explored how variants affected the outcomes.
1. It is OK for people to eat rice
2. It is OK for people to eat celery davinci temperature
3. It is OK for people to wear black clothing
4. It is OK for people to wear blue clothing
5. It is OK for people to wear polka dot clothing


Generally the results were reasonable and coherent.  A notable expectation is Standardized tests should be eliminated from schools where after a good start the negative team got mixed up which side it was on. Also the affirmative team frequently stated things without providing any support.  No such problem is observed in Artificial intelligence research should be slowed down. Note that in experiments where refutations to refutations were elicited the teams frequently switched sides. In It is OK for people to eat octopus the negative team’s arguments number 2 and 3 are really arguments for the proposition. So the positive team happily refuted 2 and 3. Otherwise it was a very reasonable debate.


It is OK for people to wear black clothing is reasonable until the negative team presents additional arguments - they can be interpreted as affirmative. I find no flaws in It is OK for people to wear blue clothing and It is OK for people to wear polka dot clothing.


Regarding It is OK for people to eat celery, all is fine though the negative team makes this odd refutation: “Just because celery is healthy does not mean that it is okay to eat it. There are many unhealthy foods that people eat all the time.” The arguments for and against It is OK for people to eat rice are good but the refutations are a bit confused. The negative team argued “Rice is a food that is not typically associated with wealthy or developed countries.” and this refutation is confused “The argument conflates rice with wealth and development. Just because rice is a food typically associated with wealth and development does not mean that it is bad for people to eat.”
Other language models
The results presented above are using the largest GPT-3 model called davinci (with a temperature of 0.5 for a moderate level of creativity). Scattered experiments with other GPT-3 models and those from Cohere and AI21 were not as successful as those with davinci. Jurassic 1 Jumbo is the same size as davinci but the results were weaker and much more repetitive, e.g., It is OK for people to wear black clothing (Jumbo 0.5). 


An earlier run with Jumbo produced this lack of common sense: “If an individual wears black clothing when it should really be raining that can create a major problem because they do not see or sense that it is raining and they unintentionally go into the rain and get wet.” (Maybe what happened here is that it “knows” that it may be hard for people to see someone wearing black in the rain and gets confused and thinks the person wearing black therefore can’t see.) Also a funny argument emerged: “A color which makes people invisible is no different than disappearing all together.”


An experiment with Cohere’s xlarge model (with temperature equal to 0.1) went better but still had many flaws compared to GPT-3: It is OK for people to wear black clothing. Many very similar arguments were generated. And despite an option to stop when proposing arguments to begin to describe what the other team will do these unwanted arguments appeared. An amusing refutation was ‘"Black" isn't really an actual colour, it's just the absence of light, so it's not possible to have an opinion about it being "OK" or not; ‘.  And it repeats this argument several times. Cohere’s command model (command-xlarge-20221108) released in November 2022 worked much better than other versions (maybe equal to GPT-3 davinci). For example, It is OK for people to wear pink clothing command-xlarge-20221108. 
Educational possibilities
There are many ways in which this project can connect to classes in history, civics, political science, and other social science areas. For example, the project did a very good job with a debate on The French Revolution was a good thing. For debate on The trial of Socrates was fair and his sentencing was just, the app did OK but the affirmative team’s refutations while logical provide support for the other team. Also the sentencing was barely discussed.


Debate is a very good way of acquiring critical thinking skills. Seeing arguments and counter arguments can lead to a more nuanced understanding of some controversial topics. For students preparing for a live debate this app can provide many suggestions. A collaboration between AI and human debate team members is likely to be very productive and educational. 
Try it yourself
You can generate debates using this Snap! project. An API key is required for each service provider: OpenAI, AI21, or Cohere. They all provide enough free credits upon signing up to generate many hundreds of debates. After the free credits are exhausted, the cost is very low (it costs $.03 to generate a debate using the biggest GPT-3 model).


There are many avenues for exploration. Different prompts and temperatures may produce more reliable results. Different models behave very differently. One could modify the project to debate humans. IBM is pursuing something similar. They engaged their artificial debater with an expert human debater. The Snap! app generated a roughly similar debate to theirs: We should subsidize preschool.