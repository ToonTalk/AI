Creating a “real” web app using ChatGPT 4
Ken Kahn <toontalk@gmail.com> - home page
Introduction
Summary of the conversation generated by ChatGPT
First session
Second session
The design
@Art Critic And do you have anything to add?
Considering a mashup of GPT 4 and Kid Pix
@Art Critic Do you have any additional suggestions?
More design ideas after “finishing” the app
Painting with random and spoken emojis
Obtaining a database of emojis
A tricky bug ChatGPT couldn’t solve
A performance problem
Dancing Emojis
The rest of the evolution of the app
Introduction
In 6 days I created what I call Emoji Adventures. It took 6 days or about 40 hours. Unlike my earlier experiments I didn’t role play a child or beginner programmer. While I intended every line of code to be written by ChatGPT, I ended up writing less than 10 lines (and they were so simple it was easier to just type them than to bother ChatGPT) out of over 1000 lines of JavaScript (and about 55 lines of HTML and 65 lines of CSS). But there were several instances where my expertise was a huge help. On the other hand there were several occasions where ChatGPT came up with better solutions than what I was thinking. And there many times it integrated some browser features that I didn’t know despite about 10 years of web development.
Summary of the conversation generated by ChatGPT
After several days ChatGPT started to be less helpful and focussed on my requests so I started a new session and uploaded the current source code and continued without problems.


Here is the first session log (Doc) and the second one (only Doc format since OpenAI doesn’t yet support logs that contain images).
First session
This conversation has been quite extensive, involving the development and refinement of an interactive web-based program that uses various features like emoji animations, speech recognition, and physics simulations. Here's a summary:


1. Initial Emoji Program: We started with a program where emojis follow the cursor or touch and respond to voice commands like "random", "bigger", "smaller", and specific emoji descriptions.


2. Black Hole Feature: Added a feature where saying "black hole" creates a black hole that attracts emojis according to gravity laws. The black hole disappears when the mouse is released or touch ends.


3. Performance Optimization: Addressed performance issues with a large number of emojis by introducing batching and updating emojis in batches per frame.


4. Speech Recognition Adjustments: Made adjustments to ensure speech recognition works effectively, handling interim and final results.


5. Using Tensorflow.js and Universal Sentence Encoder: Implemented the ability to find the closest emoji match using the Universal Sentence Encoder model in TensorFlow.js for better matching of spoken descriptions to emojis.


6. Chase Mode: Developed a "chase" mode where each emoji chases another randomly chosen emoji and disappears if caught.


7. Letter Formation: Introduced a feature to form letters and words using emojis. This involved creating invisible emojis as targets for visible ones to align into letter shapes.


8. Additional Features and Commands: Added new commands like "faster", "slower", and "spell" for various interactions like speeding up movements, slowing them down, and spelling words with emojis.


9. Debugging and Refinements: Throughout the conversation, we debugged and refined various aspects of the program, including performance optimizations, fixing bugs, and enhancing user interactions.


10. Final Touches: Made final adjustments to ensure smooth operation of all features and a cohesive user experience.


Overall, the focus has been on creating an engaging, interactive program that responds to voice commands and user interactions, suitable for young children. The program evolved significantly, integrating physics simulations, speech processing, and creative visual elements.
Second session
Throughout our conversation, we have discussed various aspects and challenges related to developing an interactive web application named "Emoji Adventures." Here's a summary of the key points and actions taken:


1. Function Modifications and Bug Fixes: We worked on several JavaScript functions to enhance the functionality of your application. This included modifying functions like `updateBlackHoleMode`, `findClosestEmojiDescription`, and `updateChaseMode` for optimized performance and correct behavior.


2. Image Generation: I generated an SVG image of a red circle with a diagonal line, as requested, for use as a stop sign in your application.


3. Responsive Design: We discussed implementing responsive design using CSS, particularly for adjusting the size and positioning of buttons on devices with different screen heights. We used media queries and viewport units (`vh`) for this purpose.


4. Dynamic Script Loading: I provided guidance on dynamically loading TensorFlow.js and the Universal Sentence Encoder (USE) scripts within a specific function (`loadUSEModel`) instead of loading them statically in the HTML.


5. Speech Synthesis and Feedback: We explored handling situations where speech synthesis isn't available by displaying text feedback. This included modifying the `speak` and `displayFeedback` functions to handle both single text strings and arrays of text.


6. Z-index and Layout Issues: We addressed issues with `z-index` and the stacking context, particularly concerning the positioning of emojis and buttons. This involved adjusting the CSS to ensure that emojis move underneath the buttons and their stop signs.


7. Troubleshooting and Code Optimization: Throughout the conversation, I provided troubleshooting advice and code optimizations for various features of your application, including handling touch and click events on new buttons, dynamically discovering a music beat threshold, and updating the layout and functionality based on user interaction.


Overall, the focus was on enhancing the interactivity, responsiveness, and functionality of the "Emoji Adventures" web application, ensuring a smooth and engaging user experience.
Highlights from the first session according to ChatGPT
In response to “Can you describe 2 or 3 highlights from the conversation that would be of interest to educators”:


Certainly! This conversation involved the development of an interactive web-based program with features that are particularly relevant and interesting for educators. Here are two key highlights:


1. Integration of Speech Recognition and Natural Language Processing: The use of speech recognition and the Universal Sentence Encoder (USE) for interpreting spoken commands is a significant educational highlight. This feature allows young learners to interact with the program using their voice, which can be especially beneficial for developing language and communication skills. The ability to recognize and respond to a variety of spoken descriptions, even if they are not exact matches to the programmed commands, demonstrates practical applications of natural language processing (NLP) in educational technology. This could inspire educators to explore how voice-activated learning tools can enhance engagement and accessibility in the classroom.
2. Physics Simulations in an Educational Context: The introduction of a "black hole" feature, where emojis are attracted to a point on the screen following the inverse square law of gravity, provides a playful yet educational demonstration of basic physics principles. This aspect of the program can be used to introduce young learners to concepts like gravity, force, and motion in a visually engaging and interactive way. By observing how emojis accelerate towards the black hole and respond to changes in size and distance, students can gain a rudimentary understanding of gravitational attraction, which can be a stepping stone to more advanced physics concepts.


These highlights showcase the potential of combining technology, education, and entertainment. They illustrate how interactive programming can be used to create educational experiences that are engaging, accessible, and informative, making learning both fun and effective for young students.


Highlights from the second session according to ChatGPT
Certainly! Here are two key highlights from our conversation that would be particularly interesting to educators:


1. Interactive Learning Tool Development: Our conversation delved into the development of an interactive web application named "Emoji Adventures." This application is designed to engage children in a playful and educational environment. For educators, this presents a fascinating case study in how interactive technology can be utilized to enhance learning and engagement. The application includes features like emoji animations responding to user commands, which can be a great tool for educators to teach programming concepts, user interaction design, and even basic animation principles in a fun and accessible way.
2. Speech Synthesis and Accessibility: We discussed the implementation of speech synthesis to make the application more interactive and accessible. This aspect is particularly relevant for educators interested in integrating technology that supports diverse learning needs. The discussion on ensuring fallback mechanisms when speech synthesis isn't available demonstrates a commitment to accessibility, ensuring that all students, regardless of their abilities or the technology available to them, can interact with and benefit from the application.


These highlights showcase the potential of technology in educational settings, emphasizing interactive learning, programming, and accessibility. The conversation provides insights into practical aspects of creating educational tools that are both engaging and inclusive.
The design
ChatGPT also aided significantly in the design. I started by entering “I've uploaded a summary of the research I've done recently. Do you have any suggestions for what I explore next?”. Seven reasonable suggestions followed and I responded ‘Please expand upon "Advanced Educational Tools Development"’. I didn’t like the seven mostly conventional ideas presented so I responded “I would like to do research aligned with Constructionism theory”. It responded with five good areas to explore but I wanted more so I entered “Do you have anything to add to this?” Four more possibilities emerged but wanted more.
@Art Critic And do you have anything to add?
Earlier I had experimented with creating custom GPTs and made an art critic GPT. Following up on one of the three suggested projects I asked ‘Do you have idea about "AI-Driven Artistic Expression" - remember I'm interested in how ChatGPT can be used by students, including young ones.’ Four good suggestions followed but I was wondering how GPT 4 might be part of the project so I wrote to the generic ChatGPT “Any suggestions how your Code Interpreter could be used by students to make visual art?”
Considering a mashup of GPT 4 and Kid Pix
After rejecting the reasonable response I then asked “I wonder if we could create something like KidPix but enhanced by using the OpenAI API? I don't want to maintain a server so I assume it should be HTML5 client based”. Good suggestions followed.


I then requested “remind me of the unique aspects of KidPix please”. Reminded of the special features of Kid Pix I then wrote
What do you think of this idea? The web page will use emojis as the equivalent of stamps. The app could rely upon speech input and output as the interface. Rather than requiring an API key, we can use the Universal Sentence Encoder to find matching emojis. Is there a database somewhere that provides a few sentence description of each emoji?


It claimed this was a unique idea. It did a Bing search of “emoji description database” and provided some reasonable suggestions of how to get the needed data.
@Art Critic Do you have any additional suggestions?
In response to the Art Critic’s seven reasonable suggestions I wrote ‘I never heard of "Speech-to-Emoji Translation" please tell me more.’ Its response was informed by its Bing search “Speech-to-Emoji Translation technology”. Reading about this research I began to plan to pursue something in this direction.
More design ideas after “finishing” the app
The app was working fine and I didn’t know what to do next so I wrote “Can you think of other features to add that would appeal to young children?” Among the twelve excellent suggestions were two that I pursued further: 
1. Emoji Dance: Create a 'dance' mode where emojis move in sync to music or rhythmic patterns, which can be entertaining and visually stimulating.
2. Pattern Formation: Implement a feature where emojis arrange themselves into various patterns or form recognizable shapes or letters.


The emoji dance worked well.


For the pattern formation I entered ‘How can we get all the emojis to do this "Pattern Formation: Implement a feature where emojis arrange themselves into various patterns or form recognizable shapes or letters."? Suppose we wanted all the letters of the alphabet’. This led to the “spell” feature of the app. ChatGPT had no problems generating a JavaScript data structure containing “ASCII art” for each letter and implementing this feature.
Painting with random and spoken emojis
After checking with ChatGPT that a large number of emojis are available in web browsers I got started by asking “OK. Let's get started. Produce a download link for a web page where a random emoji follows the cursor and a copy is dropped when the mouse is clicked.” A series of more capable apps resulted from a straightforward conversation that enabled one to “paint with emojis” using the mouse or touch events. The app could also make new emojis bigger or smaller by saying “bigger” or “smaller”.
Obtaining a database of emojis
I found the unicode.org web page describing every emoji. Using it was going to be challenging since a typical entry is


231A..231B    ; Basic_Emoji ; watch..hourglass done # E0.6   [2] (⌚..⌛)


I uploaded it to ChatGPT and entered ‘Please incorporate the emojis and their descriptions in the uploaded into the app so that if the user speaks the description of an emoji we stop randomly changing the emoji and use that one until the user says another or says "random"’. The resulting file contained too much detail. Also it didn’t deal with several technical issues that after a good deal of back forth turned the above entry into


'watch': '⌚',
'hourglass done': '⌛',
A tricky bug ChatGPT couldn’t solve
When the “black hole” feature was added only nearby emojis were attracted to the black hole. Despite many rounds of attempts by ChatGPT the problem persisted. I discovered the problem was when the change in position of an emoji was less than 1 it was updated properly but the next frame would obtain the position using parseInt to convert strings such as “42.9px” to the number 42. After I pointed out the problem to ChatGPT, it changed parseInt to parseFloat fixed the problem.
A performance problem
When there were many emojis the black hole made the app very unresponsive. It was clear to me and ChatGPT that we had to yield control instead of updating a thousand emojis. We got a batching solution to work but it looked unnatural when run. Eventually I proposed updating random emojis until a timing threshold was exceeded. This solution looks good and while some emojis might be updated several times and others not at all this averaged out pretty quickly.
Dancing Emojis
ChatGPT suggested maybe emojis could dance to music. I had no idea how to do this. ChatGPT suggested we use Web Audio API. The first version relied upon a threshold determined experimentally that was specific to a single piece of music. ChatGPT needed a little bit of guidance but came up with a solution that would have taken me much longer (not including the time to master the Web Audio API).
The rest of the evolution of the app
Here is an app that shows the evolution of the app. Initially I called the app “Pix4Kids”. Later I asked ChatGPT 4 for suggestions for better names. One was “EmojiAdventures4Kids” which I changed to “Emoji Adventures”. Here is the final version of the app. It runs well on several web browsers and devices.