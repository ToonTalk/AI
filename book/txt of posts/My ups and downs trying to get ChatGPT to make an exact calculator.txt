My ups and downs trying to get ChatGPT to make an exact calculator


toontalk@gmail.com - home page
Abstract
I aimed to create a calculator that relies on exact arithmetic and can display results in multiple formats: fractions, mixed numbers, decimals with bars over repeating digits, and scientific notation. I am satisfied with the final web app, even though it took three days to complete. The entire source code, comprising almost 400 lines of JavaScript, was generated by ChatGPT 4 (3 August 2023 version). The development journey involved five distinct phases:


1. WebDev ChatGPT Plugin: Initially, I used the WebDev ChatGPT plugin to automate the process of copying and pasting code generated by ChatGPT. However, this approach began to falter as the app grew more complex. The log.
2. Python Interpreter with ChatGPT: I then used ChatGPT with its integrated Python interpreter to further develop the JavaScript app. This allowed me to quickly upload HTML, JavaScript, and CSS files. To my surprise, ChatGPT generated Python code to edit the JavaScript file, even offering a link to download the updated version. However, over time, it started incorporating JavaScript updates incorrectly. The logs: Part 1 and Part 2.
3. Focus on Scientific Notation: I suspected that ChatGPT was struggling with the extensive context, so I decided to narrow my focus. I asked only for a function that would generate HTML for displaying fractions in scientific notation. The log.
4. Python-to-JavaScript Translation: Next, I requested a Python function to convert fractions to scientific notation. ChatGPT then translated this function into JavaScript. The log.
5. Integration: Finally, I integrated the translated JavaScript function into the app. This went smoothly.


Abstract
Exact calculators
Using the WebDev plugin
ChatGPT’s summary
The app at the end of this phase
Using ChatGPT with Python interpreter to edit JavaScript, CSS, and HTML
ChatGPT’s summary
Ups and downs
Just do the scientific notation display
Create a Python solution and then translate
ChatGPT’s summary
ChatGPT makes lots of mistakes but notices them and fixes them
Translating to JavaScript
Putting it all together
Turning numbers into words
Infinite recursion
Python to the rescue
Discussion
Exact calculators
The idea is to use rational numbers consisting of two arbitrarily large integers (limited only by available memory). A quick web search found two apps: Full Precision Calculator and calculator.net. Wolfram Alpha is also capable of this (and of course much more). Both of the apps only produce a decimal expansion where the user specifies the maximum number of digits.


My goal here was to support many different formats for the results: fraction, mixed number, decimal (with an overline for repeating digits), scientific notation (also with overlines), and English words. The final app is capable of producing 1,434,784 words for 91000000. Here are the 12,027 words for 910000. I left for future efforts to support shrinking digits (see my paper The Child-Engineering of Arithmetic in ToonTalk). ToonTalk can also do all of these formats.
Using the WebDev plugin
I started by entering “I would like to make a web page for an exact arithmetic calculator that has many different ways of displaying rational numbers”.
ChatGPT’s summary
You expressed interest in creating a web page for an exact arithmetic calculator that can display rational numbers in various formats. Here's a summary of the key points:


1. Initial Request: You wanted a calculator that can display rational numbers as fractions, mixed numbers, decimals, and percentages [I only said “many different ways of displaying rational numbers”].
2. First Version: I created a basic web-based calculator that could perform arithmetic operations and display results in the formats you specified.
3. Precision Issue: You pointed out that the calculator should not approximate fractions like 1/49 as decimals. You wanted exact values.
4. BigInteger.js Integration: To handle large integers and exact arithmetic, I integrated the BigInteger.js library into the calculator.
5. Repeating Decimals: You requested that repeating decimals be displayed with a bar over the repeating digits. I implemented this feature.
6. Percentage Format: Lastly, you wanted the percentage format to also display repeating decimals with a bar over them, which I implemented. [I believe code was generated since I can see the message containing the code sent to the WebDev plugin. But it never went any further despite a second try and waiting overnight.] 
7. Error Handling: I added error messages to the calculator to handle invalid inputs or calculations, like division by zero.
The app at the end of this phase
Here’s the app when I began to encounter repeated errors in response to “Fix percentage in a similar way”.
Using ChatGPT with Python interpreter to edit JavaScript, CSS, and HTML
I started this conversation by uploading the current JavaScript, CSS, and HTML file and entering “The decimal expansion works fine but the Percentage should work like that too”. It responded with a nice summary of the JavaScript and HTML files and asked a clarifying question.
ChatGPT’s summary
1. Initial Inquiry: You uploaded HTML, JavaScript, and CSS files for a calculator application and mentioned that while the decimal representation was working fine, the percentage representation was not.
2. File Review: I reviewed the contents of your index.html, script.js, and styles.css files. The calculator had options for various arithmetic operations and display formats, but the "Percentage" option was not implemented.
3. First Attempt: I wrote a JavaScript function called toPercentage to convert the result into a percentage in decimal form. I then attempted to integrate this function into the existing calculate() function in your script.js.
4. Issue: You reported that the percentage still displayed as a fraction, which led me to realize that the toPercentage function was not being properly called.
5. Correction: I corrected the calculate() function to correctly call toPercentage when the display format is set to "Percentage". I saved this corrected code to a new JavaScript file for you to download and test.
6. Final Steps: I provided you with the final corrected JavaScript file to replace your original script.js file for testing.


I then restarted the conversation since I thought it was losing the context.


7. Initial Setup: We started with the basic HTML and JavaScript code to perform arithmetic operations using BigInts.
8. Bug Fixes:
   * Fixed issues related to BigInt compatibility, division by zero, and syntax errors.
   * Addressed issues with displaying the result, including making sure that very large results can be viewed in a new tab.
9. Enhancements:
   * Added exponentiation functionality (^).
   * Added buttons to copy the current result into one of the number input fields.
   * Improved the UI layout.
   * Provided error messages in the UI for issues like division by zero and exceeding BigInt size.
10. Result Formatting:
   * Implemented different output formats: decimal, fraction, and percentage.
   * Added support for mixed numbers.
   * Added support for scientific notation, with specific challenges around showing repeating decimals and handling edge cases like 1/3.
11. Debugging:
   * We went through multiple iterations of debugging, including fixing syntax errors, logical errors, and UI issues.
12. HTML/CSS: Made changes to the HTML layout and added CSS for specific features like repeating decimals.
13. Code Optimization and Cleanup: Removed commented-out code, formatted the code better, and attempted to merge duplicate logic.
14. Testing: The features were tested periodically, and bugs were fixed in real-time.
Ups and downs
Typically telling ChatGPT 4 about errors soon leads to corrections. However, with the error “When I tried 1/3 as Mixed Number I see the error: alphabet.toLowerCase is not a function” I (maybe “we”) had a frustrating experience. To deal with it, ChatGPT repeatedly made editing mistakes that led to various syntax errors. Eventually, I just deleted some of the extraneous code that had been inserted in the wrong place in the file. Then the alphabet.toLowerCase error returned. It kept failing to figure this out so I suggested that maybe we needed to enhance the error handling to get more information. It modified the error handling but without providing any more information. So I removed the try/catch and reported the full error to ChatGPT.


The error turned out to be in the BigInteger.js library ChatGPT was using. I knew about how BigInt was part of JavaScript but maybe it wasn’t used much in its training data since it has been supported by most browsers for only a few years. So I took advantage of file uploading with this version of ChatGPT and uploaded a local copy of BigInt MDN documentation and suggested “JavaScript now has builtin BigInt - use it instead of the BigInt library”. It seems to be able to “read” many pages in a couple of seconds.


But its rewrite to replace the library with the new data type was very incomplete. There were many errors similar to “num1.add is not a function”. Its response caused many problems. There were many examples of rewrites like this: updated_script_bigint = updated_script_bigint.replace(".add(", " + "). This caused code such as a.add(b) to become a + b). When this mistake became apparent it added updated_script_bigint = updated_script_bigint.replace(")", "", 1). But that caused even more problems. I suggested it back up and that it needed “to keep the parens so that a.add(b) becomes (a + b)”. It kept trying to fix things but I lost patience and fixed the parentheses errors manually and uploaded the corrected version.


Now we were getting a divide by zero error when we shouldn’t. When told about it quickly figured out its mistake: if (!num2 === BigInt(0)) { instead of if (num2 !== BigInt(0)) {. Apparently in trying to fix the parentheses errors it had removed some from (!(num2 === BigInt(0))). ChatGPT fixed an instance of this problem and a copy of the problem occurred later. More errors cropped up due to the switch to BigInt such as mixing BigInts and ordinary numbers.


Results were sometimes too big for the interface. I asked ChatGPT in such cases to replace the result with a link to a new tab containing the entire result. ChatGPT’s fix seemed to work but later failed when the result needed HTML to display (e.g. overline or superscript).


It then added exponentiation at my request. When I uploaded the current index.html file it edited it incorrectly trying to add the new option. It made a new button for exponentiation rather than add it as an additional menu option. The JavaScript was edited correctly after I entered the current state of the calculate function.


Then I thought one might want to use the app to compute nested expressions so I asked for a button next to the number entry fields that copied the current result into the field. After several mistakes due to incorrect editing (I think the JavaScript was OK), it was working (though I discovered problems much later). But it broke the feature where large results are presented in a new tab. It turns out it had made two versions of displayResult. I could have asked it to merge them but I did so manually.


More bugs ensued that were due to interactions between these new features.


I then asked to add scientific notation as an option. At first it used the mantissa-e-exponent format of floating point numbers and it struggled turning it into mantissa-beween-1-and-10 10exponent. It adapted a bad strategy of accomplishing this by generating the decimal representation and then tweaking it. It would work for some cases and not others. When told about the problem different cases would work or not.


There was a problem with the link to show large results in a new tab when they involved HTML as scientific notation always does. ChatGPT successfully diagnosed the problem and introduced the use of encodeURIComponent. But it mentioned the need to use decodeURIComponent but neglected to do it. Then the new tab lacked CSS which it fixed when I reported it.


The condition for deciding if a result is too large to fit in the interface just counts string length which is inappropriate for HTML results. Its solution was to strip out the HTML in the test.


There were many backs and forth about getting the scientific notation to work in all test cases. Too often it made changes that didn’t affect the results or that broke other examples. This went on for far too long before I came up with the idea of starting a fresh session focussing on just the function that produces scientific notation HTML.
Just do the scientific notation display
I started with “I would like a JavaScript function that takes two BigInts - numerator and denominator. It should return an HTML string that displays as a number between 1 and almost 10 followed by times followed by 10 to some power. If the first part involves a repeating decimal expansion draw a bar over the repeating part.” I generated three test cases including comments of what the output should be. I worked except for fractions between 0 and 1. It tried to generate the HTML and then update it and failed repeatedly. It generated HTML that began <.span. The insertion of the decimal point was appropriate but done badly. After several backs and forth this was fixed.


But problems remained such as ⅓ becoming 0. x 100 instead of 3. x 10-1. Attempts to fix this reintroduced the <.span bug. It flailed around fixing some cases and breaking others for a long while. Reporting a problem and saying “Could you provide a detailed explanation of the program before generating it?” produced a good explanation but continued to fail to fix the problems. I tried reporting a problem after entering “Repeat the constraints of the parts of the scientific notation and then propose how to fix the code and then fix it.” The plan seemed OK but worked for some cases and broke others.
Create a Python solution and then translate
ChatGPT’s summary
1. Initial Request: You requested a Python function that takes two BigIntegers (numerator and denominator) and returns an HTML string that displays the fraction in scientific notation. The number should be between 1 and almost 10, followed by "times 10 to some power." If the number has a repeating decimal, it should be indicated with a bar over the repeating part.
2. First Attempt: I initially attempted to solve the problem but made a few mistakes, especially regarding the representation of numbers and the handling of repeating decimals.
3. Corrections and Revisions: After multiple iterations and your guidance, I managed to correct the errors. The Python function was improved to handle whole numbers, normalize fractions, and correctly represent repeating decimals. I verified its correctness through test cases.
4. Verification: To ensure accuracy, I also converted the HTML results back into Python expressions for evaluation. This helped catch a few more issues, which were then fixed.
5. JavaScript Translation: After the Python version was solidified, you requested a JavaScript version of the function, along with an HTML page for testing. The first version was created, followed by a version that utilizes JavaScript's BigInt for exact arithmetic.
6. User Interface: The HTML test page was further updated to include input fields and a button for real-time testing of the function.
7. Testing and Finalization: The JavaScript function was tested to ensure it works as expected, just like its Python counterpart.
ChatGPT makes lots of mistakes but notices them and fixes them
I started with “I would like a Python function that takes two Big Integers - numerator and denominator. It should return an HTML string that displays as a number between 1 and almost 10 followed by times followed by 10 to some power. If the first part involves a repeating decimal expansion draw a bar over the repeating part. Create a few test cases and verify that are correct.” The last sentence was inspired by the paper Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification.


What is so different about generating Python code is that I can read my email as it generates buggy code, debugs it, fixes more bugs, and so on. For example, after it iterated five times to improve the function it was able to produce this success:


  



Whoops I forgot to tell it I wanted exact arithmetic. Saying “Don't use floating point numbers - exact precision please” led to it importing the Fraction package. After 9 internal errors and fixes it produced this:
  

My response was “Looks good but 1/3 is not 3 * 0.1  - 10/11 is also wrong - can you verify by converting the HTML into Python expresions [sic] to evaluate?” On its ninth attempt to do this, I interrupted it after seeing one of its explanations:
  

I entered “Can you say what is wrong with what you wrote earlier here:” followed by a copy and paste of the above (while losing all formatting). It responded by correcting 10/11 and continued to hallucinate about ⅓. I pointed out “10/11 correction is write [sic] but 1/3 is a repeating decimal - 0.3 is not the decimal equivalent of 1/3". It responded
  



My reply was “yes - and '3.3 ×10 −1' with a bar over the second 3 matches the task”. It began adding debugging statements into the program and after twelve attempts to fix things it asked me “Would you like me to attempt another revision of the function, or would you prefer to explore a different approach?”. 


I tried to help with “Remember that for 10/11 (and 1/3) the second part should be 10 to the -1 not zero (and the mantissa adjusted appropriately)”. After 20 attempts (interspersed with checking if I wanted it to continue) it asked “It appears that my logic for setting the exponent is still incorrect for these specific cases, and I appreciate your patience as I work to resolve this issue. Would you like me to continue troubleshooting?”.


Getting tired I replied “yes and is there anyway I can help”. It replied with a summary of what it was doing and I noticed one part was “Whole Numbers: First, the function checks if the fraction is a whole number or zero. If so, it returns the whole number with an exponent of 0.” I pointed out “that isn't scientific notation. E.g. 2500 should be 2.5 x 10^3”.


In its list of steps I saw
  



My response was “Would it make sense [to] do step 6 and then 5?” It “thought” that was an excellent suggestion and thanked me for my insight. Without any errors it rewrote the function and it produced
  

My feedback was “1/3 is right except there should be bar over the second 3; 1/7 should be 1.42857142857 with a bar over 142857; 1000/3 should be 3.3 with a bar over the second 3. But the exponents look right”. This time it made a change showed some results, including remarking which ones were right or wrong, asked if it should proceed and this happened five times.


  



When asked whether to proceed, I decided to help and replied “yes. but note that 1/7 should be 1.42857142857 where the overbar is over the last part: 142857 - and 2500/1 should be 2.5 x ... and 10/11 should be 9.09 with a bar over the 09. I think I have an idea that should help. Before computing the decimal expansion keep multiplying the numerator by ten (and decrementing the exponent) while the numerator is less than the denominator. And if the numerator is more than 10 time [sic] the denominator then increment the denominator by 10 and increment the exponent. What do you think?”


This was the breakthrough! But the rewrite produced more bugs:
  



I suspected a fragment of the code and wrote “Can you explain this part of the code: while numerator > 0: …”. I responded “Looks right but why not add debugging statements to be sure”. It did so and found a bug. This led to one remaining problem with 2500/1 which it noticed and asked if it should debug it. I replied yes.


It finally had a version that produced correct results for all the tests. The final version can be found in the log file (search for “The function now correctly handles all the test cases”).
Translating to JavaScript
I then wrote “Can you translate the function to JavaScript and make some HTML for testing it on a web page”. It worked for the first time. I then asked “Can you add to the page a way to enter the numerator and denominator and push a button to the result” and was able to test it with my own inputs. I discovered that it only worked for primitive integers so I asked “Can you update it to use BigInt”. The resulting app seems to work very well.
Putting it all together
When I pasted the JavaScript function created by translating the generated Python version GPT’s response was “Your updated function provides a comprehensive approach to the problem, efficiently handling various edge cases like whole numbers and normalized fractions. The new function is well-structured and seems to be able to produce scientific notation for a wide range of inputs, which is great!”. And it provided a good overview of the function.


A remaining task was that the app only generated scientific notation when dividing. But 10+10 is not 20 but is 2 x 101. It made it work for any operator easily.


When testing I noticed “When I do 123/999 in decimal notation I see .123123 with bar over all digits. While not wrong .123 with a bar over 123 is preferred.” After a little back and forth it was fixed.


I then wrote “When I add 500+500 in Scientific Notation I see 1.000 x 103 (3 superscripted). I think 1 x 103 is better”. It fixed that easily.


I had never asked for “Percentage” as a format and while testing it I saw some problems. So I asked ChatGPT “Let's remove percentage as a feature from index.html: …”. I then asked it to cleanup the unneeded code supporting percentage from the entire script.js file. Its response included many comments such as “// ... your existing toDecimal code …” so this wasn’t helpful. When I gave it the function that called toPercentage it responded with a cleaner refactored version. More than I asked for but nice.


The next problem is that the buttons that copy results into a number field didn’t handle HTML results. After some back and forth the buttons only work if the result is an integer regardless of format and otherwise informs the user that only integer values are allowed.


The last task was to provide an “about” field. I asked “Let's add a note to the bottom of the app that briefly explains what the app does and includes a link (https://docs.google.com/document/d/1KCpYxtcS6-HyDIDh9Zh011MEQHeYDRxzQhNXRkcYCcw/edit?usp=sharing) to learning how it was made with the help of ChatGPT 4”. It generated a nice footnote and when asked to add CSS it looked much better.
Turning numbers into words
After doing all this and writing this document I decided to have fun adding “English” as a new format. I recalled reading that John Conway had come up with an extensible scheme for naming numbers with thousands or millions of digits. So I asked ChatGPT in a fresh session “Can you generate a JavaScript function that takes a BigInt as input and returns an English string that corresponds to that number. Use Conway's scheme for naming very large numbers.”.
Infinite recursion
It generated a web app along with some test cases that worked unless the number was between 100 and 1000. It could handle 10^300 but for 10^300+234 (or just 234) it would cause a stack overflow. The problem was in the recursion where it handled numbers less than or equal to 100 correctly. The problem was with numbers less than a million it recurred with n/1000 and n%1000. The frustrating thing was how long it took ChatGPT to understand this problem and fix it. It helped to ask it to add debugging statements. After a very long exchange it finally introduced a case for numbers between 100 and 1000 to fix the problem.


But infinite recursion reappeared for 1234567890123456789. Again it took ChatGPT several iterations to fix the recursion to deal generally with numbers greater than one million. But its fix introduced other bugs. I reported them but it kept handling special cases instead of fixing it properly. My last thing I told it was “I'm getting "one centduoduoillion" for 10^401 and 10^400. But something is really wrong 10^9 and 10^10 show as "ten trillion". Progress was so slow I decided to start again.


Python to the rescue
In a new session I repeated my original request but asked for a Python function. I also added “Verify test examples” to the prompt. After three internal bug fixes (I was able to read email as it was working), it came up with a function that passes these tests:
* 123 → "one hundred and twenty-three"
* 456,789 → "four hundred and fifty-six thousand seven hundred and eighty-nine"
* 123,456,789,012 → "one hundred and twenty-three billion four hundred and fifty-six million seven hundred and eighty-nine thousand twelve"
* 123,456,789,012,345,678,901,234,567,890 → "one hundred and twenty-three quindecillion four hundred and fifty-six quattuordecillion seven hundred and eighty-nine tredecillion twelve duodecillion three hundred and forty-five undecillion six hundred and seventy-eight trillion nine hundred and one billion two hundred and thirty-four million five hundred and sixty-seven thousand eight hundred and ninety"


I then asked to translate the function to JavaScript. In doing so it wasn’t careful to always use the BigInt datatype. After fixing that I asked ChatGPT to integrate the ability to turn numbers into words into the exact calculator app. I uploaded the JavaScript, HTML, and CSS. It inserted the new menu option in the wrong place in the file and failed to fix the problem when I pointed it out. So I asked it to tell me what changes I should make to the files. That worked.


While testing the app I encountered a result that was “"one undefined two quattuordecillion". When ChatGPT fixed that, other problems showed up. Eventually it was working for numbers less than 10^51. So I asked to make it more general. Its fix worked for numbers up to 10^300. 


After many partial fixes I suggested we go back to getting the Python version to work and translate again. The Python version worked for a 10^401+1 ("ten duocentillion novemnovemcentillion one") and it went ahead and translated to JavaScript. Once again it didn’t remember to consistently use the BigInt datatype. It mistakenly believed that BigInt didn’t support exponentiation and implemented its own but again mixed BigInts and Numbers. Only when I gave it the latest documentation did it use BigInt exponentiation.


Many bugs followed so again suggested we get it right in Python again. It claimed the function was working and proceeded to translate to JavaScript aftering claiming “the results seem more accurate:”
10^300 : 'one octonovemillion'
10^400 : 'one centduoduoillion'
10^401:  'one centduotreillion'
10^402 : 'one centduotreillion'


Clearly nonsense. After pointing that out ChatGPT reworked the Python version and reported:


10^9: 'one billion'
10^10 : 'ten billion'
10^400: 'one duocentillion'
10^401: 'ten duocentillion'


I thought it needs more test cases so I wrote “Looks good. How about 10^99, 10^100, and 10^101. And 5*10^400+52”. After many internal iterations ChatGPT responded


10^99 : one vigintiduoillion
10^100 : ten vigintiduoillion
10^101:: one hundred vigintiduoillion
5×10^400+52: five centillion fifty-two


After I asked for the JavaScript translation I found more incorrect results. I found complaining about errors to the JavaScript and copying and pasting log files to ChatGPT tiresome, so I entered “Let's go back to testing the Python version. Let's test 123, 123456, 123456789, 1234567890123456789, and many more like this”.


And I finally got a version that seems to work well!


I could have continued to work with ChatGPT to turn non-integers into words but I did it manually by entering about five lines of code. 
Discussion
I clearly did not demonstrate that a complex web app can easily be created by ChatGPT. There were three major problems: 
1. When ChatGPT generates Python code to update a JavaScript file and the edits are correct it is a nice accelerator but when it makes mistakes it can waste huge amounts of time.
   * Probably ChatGPT will improve its ability to edit source code but until then best to manually copy and paste instead.
2. Once ChatGPT adopted the plan to transform the decimal notation of a rational number to scientific notation it continually missed some cases and fixing them led to different cases. 
   * Fixing a bad coding plan is not easy. In my case, I needed to suggest a new strategy in a few sentences.
3. ChatGPT’s context is currently limited (4k tokens for ChatGPT Plus) and it is easy to notice that after a while it makes mistakes due to forgetting code or explanations it generated earlier.
   * The 32k token context version of GPT 4 isn’t available to me but is likely to become available over time. Claude 2 has a 100k limit and does pretty well on programming tasks.
   * A good workaround is to isolate a single function and work with ChatGPT in a fresh conversation to perfect it and then integrate it back into the whole project.


I found (too late) that the most effective way to construct an app like this is to:
1. Ask for a Python version and then test it well before asking for the JavaScript translation.
2. After ChatGPT generates the large-scale framework for the app it is best to start new sessions to fully develop and test each individual function.
3. Regarding testing, ChatGPT generated four or five decent tests but they weren’t enough so suggesting many more leads to better and quicker results.


After doing all this I discovered a Python library num2words and tested it here. ChatGPT did early on try to BigInteger.js and after some problems I suggested it just use the builtin BigInt data type. Perhaps a mistake.


Here’s the resulting final web app.


Comments and questions welcome. I’m at toontalk@gmail.com