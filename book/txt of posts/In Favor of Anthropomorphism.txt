In Favor of Anthropomorphism
Ken Kahn <toontalk@gmail.com>


In Hello World Issue 22 on Teaching & AI Ben Garside wrote the article “How anthropomorphism hinders AI education”. This was apparently based on his earlier blog post. He argues against using terms such as learn, believe, know, and the like when talking about AI systems. This has been a topic of discussion since at least the 1970s. John McCarthy who led the Stanford AI lab in 1979 wrote Ascribing Mental Qualities to Machines. He goes as far as arguing that it makes sense to talk about whether the thermostat mistakenly believes it is too cold as an explanation as to why the furnace is on. Dan Dennett published a philosophy journal article in 1971 (Intentional systems) defending the idea that sometimes the best way to understand a machine is by taking an intentional stance (something with goals, beliefs, and intentions). He later expanded this in his book the Intentional Stance. Some thought that this was a huge mistake in the spirit of Ben’s Hello World article. Drew McDermott, for example, wrote Artificial Intelligence meets Natural Stupidity (published in 1981). Arguments about anthropomorphism in computer terminology are even older. There were arguments that saying a computer has memory is too anthropomorphic and one should refer to its “store” instead.


Avoiding cognitive terms when talking about and interacting with today’s AI systems reminds me of the exercise of using only the one thousand most common English words. (See the very funny Thing Explainer by Randall Monroe.) It makes communication much harder. We can usefully talk about a chatbot doing reasoning even if there is some debate of whether it “really” does. Chatbots are not completely black boxes, one can look inside and find symbols and reasoning. See, for example, Ellie Pavlick’s 2023 article Symbols and grounding in large language models in the Philosophical Transactions of the Royal Society. An excellent collection of such studies can be found at transformer-circuits.pub and distill.pub/2020/circuits.


Instead of telling children AIs are just tools designed by people, I think we should tell them that AIs aren’t people and they aren’t alive but interacting with them as if they are is often the most effective way to use them.