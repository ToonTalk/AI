A comparison of ChatGPT 4 and the ship’s computer in Star Trek Next Generation’s Schism episode


Ken Kahn <toontalk@gmail.com>


An attempt to recreate the holodeck visualization based on ChatGPT’s approximate memory of the episode        1
ChatGPT’s visualization compared to what the Enterprise computer was commanded        2
Discussion        5


More than 30 years ago I saw a Star Trek Next Generation episode where crew members, as Wikipedia describes, “use the holodeck to reconstruct and refine their fragmented memories and impressions of the events”. Today (31/8/2023) had this conversation with ChatGPT 4.
An attempt to recreate the holodeck visualization based on ChatGPT’s approximate memory of the episode


I asked if it remembered the episode. While I could (and later did) Google it, instead I entered “Do know [sic] the STNG episode where Riker and others are asking the computer to visualize what they were dreaming about?”. It came up with a different episode so I continued with “I remember they describe an operating table to the computer and it shows it to them. And then they provide corrections until they all agreed it matched their dreams. Aliens were doing something to them as they slept.” I then wrote “Good. Do you know what they first say in the holodeck to start the visualization process?” and it gave a mostly accurate response (it hallucinated a discussion of a door).


In a crude attempt to recreate the holodeck scene in the episode I entered “Can you create a three.js web page that corresponds to what Riker said to start things?” It responded with HTML and JavaScript that displays a door. I then asked for the camera to move around. Then adding what ChatGPT remembered Troi saying the page now also had a legless table. When I mentioned that tables have legs, it added four legs but it located a pair of legs at the same location so it looked like only two legs. The table and door were colliding. And the tabletop was vertical. I complained about all three problems at once which was probably a mistake since it only fixed the table door collision. Complaining about the two remaining problems produced no change in the code. When asked what was different, ChatGPT apologized and it fixed the problems. I then pointed out that the bottom of the legs and the bottom of the door should be on the floor and suggested fixing that and displaying the floor. It fixed things and added a floor that couldn’t be seen. When I complained about that it said it was the lighting and camera angle and generated a page where the floor is visible.
ChatGPT’s visualization compared to what the Enterprise computer was commanded
I could have continued but instead explored what would happen if I copied the commands to the Enterprise computer to ChatGPT. I found a transcript of the episode and here’s the resulting ChatGPT 4 conversation. I began with the first command


Troi: …Computer, show me a table.
Computer: There are five thousand forty seven classifications of tables on file. Specify design parameters.


Me: Computer show me a table (using three.js to create a web page)
ChatGPT: Here is a basic example of how you might use Three.js to create a table as a 3D object in a web page. Note that this is a simple and generalized implementation. You will need to adjust parameters like colors, dimensions, and positions to fit your specific needs. Here is the page with a table


I then asked ChatGPT “Add controls to move the camera around” since I wasn’t on the holodeck. It made several mistakes importing the Three.js OrbitControls and eventually I just copied and pasted the appropriate documentation. The result was a page where one can move around to see the table from different angles and distances.


  

A scene from the episode




LaForge: …Computer, reduce the height of the table by twenty five percent.


When I repeated LaForge’s instruction, ChatGPT just moved the tabletop and legs but didn’t change the size. When I pointed this out the legs were shorter but no longer connected to the tabletop. After a short exchange it fixed that and the table was shorter.


Worf: No, the table was smaller. And it was inclined. Computer, decrease the table's surface area by twenty percent and incline the top fifteen degrees.
Troi: Computer, make this a metal table.


I unfortunately missed Worf’s command and entered Troi’s. (So I added it at the very end of the conversation.) The result was a black page since with the new material it needed proper lighting. When that was fixed the table still looked wooden.


Troi: Computer, lower the surrounding light level.


Several errors later the table was gray and the light was dim. The errors seemed to be due to ChatGPT losing the context and repeating errors that it had fixed earlier. So I started a new conversation and began it by pasting in the source code of the most recently generated page.


LaForge: There was a light right in my face. A bright light. Computer, give me a bright light right above the table.
Computer: Specify light source.
LaForge: I couldn't tell. It was above me. An overhead lamp.
Computer: Estimated distance of light source.
LaForge: I don't know. It was at least two or three meters above. Brighter. Brighter.


Me: Computer, give me a bright light right above the table.
ChatGPT: We'll add a PointLight source in your scene to simulate a light above the table. The PointLight simulates a single point source of light that casts light in all directions from its position.


I didn’t see the change with the page with the new point light because it looks different only from certain camera positions. When I mistakenly complained I didn’t see any difference, ChatGPT changed the material of the tabletop to be more reflective.


Troi: Computer, create a restraining arm attached to the right side of the table, at the midpoint.


ChatGPT, when given the same command, added a pole to the midpoint of one of the short sides of the table. Complaining about the location moved it a bit.


RIKER: Computer, put controls on the restraining arm. A control panel. Lights.


ChatGPT’s response was to add two “LED” lights to the pole.


Kaminer: There was something else there. Over the head of the table. A metal swing arm. Computer, create a metal swing arm, double jointed, total length one meter. Connect it to the head of the table.


ChatGPT added a new pole and for some reason shrank the existing pole. And both were floating over the table.


Worf: …Computer, produce a pair of scissors attached to the armature. The handle is wrong. It was not scissors. Computer, make the handle a single grip ten centimeters long, solid metal. Now make one blade longer, curved inward. And give the other blade a jagged edge.


When ChatGPT was given Worf’s instructions it did manage to add something to the top of the new pole that is scissor-like and even has a jagged edge (move the camera above and zoom in to see this).


I then noticed I had missed an earlier instruction from Worf so I added it now.


Worf: Computer, decrease the table's surface area by twenty percent and incline the top fifteen degrees.


It correctly updated the tabletop but neglected to keep the legs connected. It explained it reduced the surface area by approximately 20% by shrinking it 90% in each dimension resulting in a 19% reduction.


Entering “Good. But the legs are no longer connected to the tabletop” improved things but the top of the legs don’t really connect with a slanted tabletop well.


  
  

Screenshots of the final visualization by ChatGPT 
(note that the script calls for a dark room with a bright spotlight from above)
(note also that the two red spots are red light sources representing LEDs)
Discussion
The Star Trek computer sometimes demanded much more detail before complying and sometimes it demanded nothing and added many details not specified in the instructions from the crew. ChatGPT, in contrast, always just took its best guess and didn’t embellish. Both demonstrated the idea of incremental refinements of the visualizations via additional dialogues.


There are many shortcomings in ChatGPT’s visualizations. My experience is that many of these problems can be fixed by a good more back and forth. You are welcome to try it.


In the beginning of the Star Trek visualization scene the incremental changes to the virtual object were plausible. But when asked to make the table metal it suddenly became a strange complex contraption. Pretty implausible and inconsistent with the earlier interactions.


  

Final visualization in the episode


Maybe the next generation of chatbots will perform as well as the Enterprise’s computer.
  

This document’s QR code generated by this generative AI model given the prompt “Star Trek holodeck”